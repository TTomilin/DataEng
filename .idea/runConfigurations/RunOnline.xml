<component name="ProjectRunConfigurationManager">
  <configuration default="false" name="RunOnline" type="SubmitSparkJob_Configuration" factoryName="HDInsight Spark" editBeforeRun="true">
    <module name="data-eng" />
    <spark-job-configuration>
      <local-run>
        <spark-local-run-configurable-model>
          <is-parallel-execution>false</is-parallel-execution>
          <is-pass-parent-envs>true</is-pass-parent-envs>
          <program-parameters />
          <working-directory>file://$PROJECT_DIR$</working-directory>
          <envs>
            <map />
          </envs>
          <vm-parameters />
          <main-class>nl.dataeng.tue.Application</main-class>
          <classpath-module>data-eng</classpath-module>
          <data-root>file://$PROJECT_DIR$/data</data-root>
        </spark-local-run-configurable-model>
      </local-run>
      <focused-tab-index>1</focused-tab-index>
      <spark_submission artifact_name="data-eng:jar_extracted" cluster_mapped_id="data-eng-new" cluster_name="data-eng-new" is_local_artifact="false" job_name="RunOnline" local_artifact_path="$PROJECT_DIR$/data_eng_jar/data-eng.jar" classname="nl.dataeng.tue.Application">
        <cmd_line_args />
        <jobConfigs>
          <array>
            <option value="driverMemory" />
            <option value="28G" />
          </array>
          <array>
            <option value="driverCores" />
            <option value="8" />
          </array>
          <array>
            <option value="executorMemory" />
            <option value="48G" />
          </array>
          <array>
            <option value="executorCores" />
            <option value="32" />
          </array>
          <array>
            <option value="numExecutors" />
            <option value="1" />
          </array>
        </jobConfigs>
        <ref_files />
        <ref_jars />
        <ssh_cert auth_type="UsePassword" private_key_path="" user="sshuser" remote_debug_enabled="true" />
        <job_upload_storage storage_account="dataengnewhdistorage" upload_path="wasbs://data-eng-new-2020-06-03t11-45-37-990z@dataengnewhdistorage.blob.core.windows.net/SparkSubmission/" selected_container="data-eng-new-2020-06-03t11-45-37-990z" storage_account_type="BLOB" adl_root_path="" />
      </spark_submission>
    </spark-job-configuration>
    <method v="2">
      <option name="BuildArtifacts" enabled="true">
        <artifact name="data-eng:jar_extracted" />
      </option>
    </method>
  </configuration>
</component>